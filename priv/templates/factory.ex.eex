defmodule <%= module %> do
  @moduledoc """
  Factory for creating agents with consistent configuration.

  This module centralizes agent creation, ensuring all agents use the same
  model, middleware stack, and base configuration. The Coordinator calls
  `create_agent/1` when starting a conversation session.

  This Factory is automatically configured for your persistence layer:
  - Owner type: :<%= owner_type %>
  - Owner field: <%= owner_field %>
  - Conversations context: <%= conversations_module %>

  ## Customization

  - Change model provider in `get_model_config/0`
  - Configure fallbacks in `get_fallback_models/0` (TODO: wire into Agent.new)
  - Configure title generation model in `get_title_model/0`
  - Modify system prompt in `base_system_prompt/0`
  - Add/remove middleware in `build_middleware/3`
  - Configure HITL in `default_interrupt_on/0`
  - Override filesystem scoping in `get_filesystem_scope/1`

  ## Understanding the Default Middleware

  The middleware stack below replicates `Sagents.Agent.build_default_middleware/3`.
  You can call that function in IEx to see the canonical defaults:

      middleware = Sagents.Agent.build_default_middleware(model, "test-agent")

  ## Model Fallback Strategy

  The fallback configuration uses the *same model* on a different provider
  for resilience without changing behavior:

  | Primary Provider      | Fallback Provider       |
  |-----------------------|-------------------------|
  | ChatAnthropic (API)   | ChatAnthropic (Bedrock) |
  | ChatOpenAI (API)      | ChatOpenAI (Azure)      |

  ## Filesystem Scoping

  The FileSystem middleware supports flexible scoping to control file isolation.

  **For user-facing interactive agents (recommended):**
  - **User-scoped**: `filesystem_scope: {:user, user_id}`
    - Files persist across all conversations for the same user
    - Enables true long-term memory and file accumulation
    - This is the typical pattern for chat applications

  **Other scoping options:**
  - **Project-scoped**: `filesystem_scope: {:project, project_id}`
    - Files shared within a project across multiple users and conversations

  - **Agent-scoped**: `filesystem_scope: nil` (defaults to `{:agent, agent_id}`)
    - Files isolated per conversation - typically too limiting for user-facing agents
    - May be appropriate for non-interactive batch processing or isolated task execution

  - **Custom scoping**: Use any tuple like `{:team, team_id}` or `{:session, session_id}`

  **Important:** The Coordinator should pass the appropriate scope when calling `create_agent/1`.

  """

  alias LangChain.ChatModels.ChatAnthropic
  # Uncomment for OpenAI:
  # alias LangChain.ChatModels.ChatOpenAI
  # Uncomment for Bedrock:
  # alias LangChain.Utils.BedrockConfig
  alias Sagents.Agent
  alias Sagents.Middleware.ConversationTitle
  alias Sagents.Middleware.HumanInTheLoop

  # ---------------------------------------------------------------------------
  # Model Configuration (edit these module attributes to change models)
  # ---------------------------------------------------------------------------

  # Primary model for agent conversations
  # See: https://docs.anthropic.com/en/docs/models-overview
  @main_model "claude-sonnet-4-5-20250929"

  # Title generation uses a lighter/faster model for cost efficiency
  # Haiku is ~10x cheaper than Sonnet and sufficient for generating titles
  @title_model "claude-3-5-haiku-latest"
  # Uncomment when using Bedrock fallback:
  # @title_fallback_model "us.anthropic.claude-3-5-haiku-20241022-v1:0"

  # For OpenAI, uncomment and use:
  # @main_model "gpt-4o"
  # @title_model "gpt-4o-mini"

  @doc """
  Creates an agent with the standard configuration.

  ## Options

  - `:agent_id` - Required. Unique identifier for this agent.
  - `:conversation_id` - Optional. Conversation ID to automatically load filesystem scope.
    When provided, calls `get_filesystem_scope/1` to determine the scope based on the
    conversation's <%= owner_field %>.
  - `:filesystem_scope` - Optional. Explicit scope tuple for filesystem isolation.
    Examples: `{:<%= owner_type %>, <%= owner_field %>}`, `{:project, 456}`, `{:team, 789}`.
    If neither `:conversation_id` nor `:filesystem_scope` is provided, defaults to `{:agent, agent_id}`.
  - `:timezone` - Optional. IANA timezone string (default: "UTC").
  - `:interrupt_on` - Optional. Map of tool names requiring approval.
    Pass `nil` to disable HITL entirely.

  ## Examples

      # Recommended: Pass conversation_id for automatic user-scoped filesystem
      {:ok, agent} = Factory.create_agent(
        agent_id: "conv-123",
        conversation_id: 123
      )

      # Explicit filesystem scope (bypasses get_filesystem_scope/1)
      {:ok, agent} = Factory.create_agent(
        agent_id: "conv-123",
        filesystem_scope: {:<%= owner_type %>, current_<%= owner_type %>.id}
      )

      # Agent-scoped (isolated per conversation - typically too limiting)
      {:ok, agent} = Factory.create_agent(agent_id: "conv-123")

      # With timezone
      {:ok, agent} = Factory.create_agent(
        agent_id: "conv-123",
        conversation_id: 123,
        timezone: "America/New_York"
      )

      # Disable human-in-the-loop
      {:ok, agent} = Factory.create_agent(
        agent_id: "conv-123",
        conversation_id: 123,
        interrupt_on: nil
      )

      # Custom HITL configuration
      {:ok, agent} = Factory.create_agent(
        agent_id: "conv-123",
        conversation_id: 123,
        interrupt_on: %{
          "write_file" => true,
          "delete_file" => true,
          "execute_command" => true
        }
      )

  """
  def create_agent(opts \\ []) do
    agent_id = Keyword.fetch!(opts, :agent_id)
    conversation_id = Keyword.get(opts, :conversation_id)
    timezone = Keyword.get(opts, :timezone, "UTC")
    interrupt_on = Keyword.get(opts, :interrupt_on, default_interrupt_on())

    # Get filesystem scope - priority: explicit :filesystem_scope > :conversation_id > default
    filesystem_scope = case Keyword.get(opts, :filesystem_scope) do
      nil when not is_nil(conversation_id) ->
        # Auto-load scope from conversation
        get_filesystem_scope(conversation_id)

      explicit_scope ->
        # Use explicit scope (may be nil, which defaults to {:agent, agent_id})
        explicit_scope
    end

    Agent.new(
      %{
        agent_id: agent_id,
        model: get_model_config(),
        base_system_prompt: base_system_prompt(),
        middleware: build_middleware(filesystem_scope, interrupt_on, timezone)
      },
      # Since we specify the full middleware stack, don't add defaults
      replace_default_middleware: true
    )
  end

  @doc """
  Gets the filesystem scope for a conversation.

  This function is called automatically when `:conversation_id` is passed to
  `create_agent/1`. It looks up the conversation in the database and returns
  a scope tuple based on the conversation's <%= owner_field %>.

  For user-facing agents, this returns `{:<%= owner_type %>, <%= owner_field %>}` to enable
  persistent memory across conversations for the same <%= owner_type %>.

  ## Customization

  Override this function to implement different scoping strategies:

      # Current implementation (user-scoped by default)
      def get_filesystem_scope(conversation_id) do
        case <%= conversations_module %>.get_conversation(conversation_id) do
          nil -> nil
          conversation -> {:<%= owner_type %>, conversation.<%= owner_field %>}
        end
      end

      # Project-scoped alternative
      def get_filesystem_scope(conversation_id) do
        case <%= conversations_module %>.get_conversation_project(conversation_id) do
          nil -> nil
          project_id -> {:project, project_id}
        end
      end

      # Agent-scoped (isolated per conversation)
      def get_filesystem_scope(_conversation_id), do: nil

  Returns a scope tuple like `{:<%= owner_type %>, <%= owner_field %>}` or `nil` for agent-scoped.
  """
  def get_filesystem_scope(conversation_id) do
    # Default: <%= String.capitalize(owner_type) %>-scoped filesystem for persistent memory across conversations
    # Load the conversation and extract the <%= owner_field %>
    case <%= repo_module %>.get(<%= conversations_module %>.Conversation, conversation_id) do
      nil -> nil
      conversation -> {:<%= owner_type %>, conversation.<%= owner_field %>}
    end
  end

  # ---------------------------------------------------------------------------
  # Model Configuration
  # ---------------------------------------------------------------------------

  # Primary model configuration.
  # Modify this function to switch providers or models.
  defp get_model_config do
    ChatAnthropic.new!(%{
      model: @main_model,
      api_key: System.fetch_env!("ANTHROPIC_API_KEY"),
      stream: true
    })

    # OpenAI alternative:
    # ChatOpenAI.new!(%{
    #   model: @main_model,
    #   api_key: System.fetch_env!("OPENAI_API_KEY"),
    #   stream: true
    # })
  end

  # Fallback models - same model on different infrastructure for resilience.
  # These are used when the primary provider is unavailable.
  #
  # TODO: Wire this into Agent.new when fallback support is added.
  # Currently this function is defined for future use.
  #
  # Note: To use Bedrock fallback, configure AWS credentials in config.exs:
  #
  #   config :langchain, :bedrock,
  #     aws_access_key_id: System.get_env("AWS_ACCESS_KEY_ID"),
  #     aws_secret_access_key: System.get_env("AWS_SECRET_ACCESS_KEY"),
  #     aws_region: System.get_env("AWS_REGION", "us-east-1")
  #
  # Then uncomment the BedrockConfig alias at the top of this file.
  #
  @doc false
  def get_fallback_models do
    [
      # Anthropic via AWS Bedrock (same Claude model, different provider)
      # Uncomment when Bedrock is configured:
      # ChatAnthropic.new!(%{
      #   model: "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
      #   bedrock: BedrockConfig.from_application_env!(),
      #   stream: true
      # })

      # OpenAI via Azure alternative:
      # ChatOpenAI.new!(%{
      #   model: @main_model,
      #   endpoint: "https://your-resource.openai.azure.com",
      #   api_key: System.fetch_env!("AZURE_OPENAI_API_KEY"),
      #   api_version: "2024-02-15-preview"
      # })
    ]
  end

  # ---------------------------------------------------------------------------
  # Title Generation Model
  # ---------------------------------------------------------------------------

  # Title generation uses a lighter/faster model for cost efficiency.
  # Haiku is ~10x cheaper than Sonnet and sufficient for generating titles.
  defp get_title_model do
    ChatAnthropic.new!(%{
      model: @title_model,
      api_key: System.fetch_env!("ANTHROPIC_API_KEY"),
      temperature: 1,
      stream: false
    })
  end

  # Fallback models for title generation
  defp get_title_fallbacks do
    [
      # Uncomment when Bedrock is configured (also uncomment BedrockConfig alias):
      # ChatAnthropic.new!(%{
      #   model: @title_fallback_model,
      #   bedrock: BedrockConfig.from_application_env!(),
      #   temperature: 1,
      #   stream: false
      # })
    ]
  end

  # ---------------------------------------------------------------------------
  # System Prompt
  # ---------------------------------------------------------------------------

  # Base system prompt for all agents.
  # Customize this for your agent's purpose and personality.
  defp base_system_prompt do
    """
    You are a helpful AI assistant.
    """
  end

  # ---------------------------------------------------------------------------
  # Human-in-the-Loop Configuration
  # ---------------------------------------------------------------------------

  # Default tools that require human approval before execution.
  # Return `nil` or `%{}` to disable HITL entirely.
  #
  # Configuration options:
  #   - `true` - Enable with default decisions (approve, edit, reject)
  #   - `false` - No interruption for this tool
  #   - `%{allowed_decisions: [:approve, :reject]}` - Custom decisions
  #
  defp default_interrupt_on do
    %{
      "delete_file" => true
      # "write_file" => true,
      # "execute_command" => true
    }
  end

  # ---------------------------------------------------------------------------
  # Middleware Configuration
  # ---------------------------------------------------------------------------

  # Build the middleware stack.
  #
  # This replicates the default stack from `Sagents.Agent.build_default_middleware/3`:
  #   1. TodoList - Task management with write_todos tool
  #   2. ConversationTitle - Auto-generate conversation titles (async, so positioned early)
  #   3. FileSystem - Virtual filesystem (ls, read_file, write_file, etc.)
  #   4. SubAgent - Delegate to specialized child agents
  #   5. Summarization - Compress long conversations to stay within token limits
  #   6. PatchToolCalls - Fix dangling tool calls from interrupted conversations
  #
  # HumanInTheLoop is conditionally added based on `interrupt_on` configuration.
  #
  # Order matters! Early middleware sees messages first (before_model) and
  # processes responses last (after_model).
  #
  defp build_middleware(filesystem_scope, interrupt_on, _timezone) do
    [
      # Task management - gives the agent a todo list for tracking work
      Sagents.Middleware.TodoList,

      # ConversationTitle - auto-generate titles after the first exchange.
      # Positioned early because it's async and should start as soon as possible.
      # Uses a lighter/faster model (Haiku) for cost efficiency.
      {ConversationTitle, [
        chat_model: get_title_model(),
        fallbacks: get_title_fallbacks()
      ]},

      # Virtual filesystem - file operations with configurable scope
      # For user-facing agents, pass {:user, user_id} from the Coordinator
      # If nil, defaults to {:agent, agent_id} (isolated per conversation)
      {Sagents.Middleware.FileSystem, [filesystem_scope: filesystem_scope]},

      # SubAgent - spawn child agents for complex tasks
      # Configure block_middleware to prevent certain middleware from being
      # inherited by subagents (e.g., Summarization, ConversationTitle).
      {Sagents.Middleware.SubAgent, [
        block_middleware: [
          Sagents.Middleware.Summarization,
          Sagents.Middleware.ConversationTitle
        ]
      ]},

      # Summarization - compress long conversations to fit context window
      Sagents.Middleware.Summarization,

      # PatchToolCalls - fix dangling tool calls from interrupted conversations
      Sagents.Middleware.PatchToolCalls
    ]
    # Conditionally add HumanInTheLoop if interrupt_on is configured.
    |> HumanInTheLoop.maybe_append(interrupt_on)
  end
end
